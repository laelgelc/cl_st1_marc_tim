{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07763ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now cluster our self-trained Wikipedia discussions model\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(\"wue15_word2vec.model\")\n",
    "model = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the words and their vectors\n",
    "words = model.index_to_key\n",
    "word_vectors = model[words]\n",
    "print(\"Number of vectors to be clustered:\", len(word_vectors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d754c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "# We will use the KMeans clustering algorithm\n",
    "# We need to choose a number of clusters (k)\n",
    "# We will not use too many clusters so it goes fast\n",
    "k = 500\n",
    "\n",
    "# An alternative would be to take a certain percentage, e.g. 2.4 % of the number of types\n",
    "# k = int(len(word_vectors) * 0.024)\n",
    "\n",
    "print(\"Number of clusters:\", k)\n",
    "kmeans = cluster.KMeans(n_clusters=k)\n",
    "kmeans.fit(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model\n",
    "with open(\"kmeans_wue15_word2vec.pkl\", \"wb\") as f:\n",
    "    pickle.dump(kmeans, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Read the model\n",
    "with open(\"kmeans_wue15_word2vec.pkl\", \"rb\") as f:\n",
    "    kmeans = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are the cluster IDs for each word\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dictionary to map words to their cluster IDs\n",
    "\n",
    "word_cluster = dict(zip(words, kmeans.labels_))\n",
    "print(word_cluster)\n",
    "\n",
    "cluster_words = {}\n",
    "for word, cluster in word_cluster.items():\n",
    "    if cluster not in cluster_words:\n",
    "        cluster_words[cluster] = []\n",
    "    cluster_words[cluster].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cluster_centroid = {}\n",
    "for cluster, words in cluster_words.items():\n",
    "    vectors = [model[word] for word in words]\n",
    "    cluster_centroid[cluster] = np.mean(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame for cluster assignment and similarity\n",
    "df = pd.DataFrame(word_cluster.items(), columns=[\"word\", \"cluster\"])\n",
    "df[\"sim\"] = [\n",
    "    1 - distance.cosine(model[word], cluster_centroid[cluster])\n",
    "    for word, cluster in word_cluster.items()\n",
    "]\n",
    "df = df.sort_values(by=[\"cluster\", \"sim\"], ascending=[True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d759a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90769a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cluster[\"attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"post\"\n",
    "cluster = word_cluster[word]\n",
    "cluster_words[cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71507875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create top-3 word labels for each cluster\n",
    "cluster_label = {cluster: \"|\".join(words[:3]) for cluster, words in cluster_words.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b349c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951505ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dic, reverse=True):\n",
    "    \"\"\"\n",
    "    Sort a dictionary by its values.\n",
    "\n",
    "    Args:\n",
    "        dic (Dict): Dictionary to sort.\n",
    "        reverse (bool): Whether to sort in descending order.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Sorted dictionary.\n",
    "    \"\"\"\n",
    "    return dict(sorted(dic.items(), key=lambda item: item[1], reverse=reverse))\n",
    "\n",
    "\n",
    "def get_similar_clusters(\n",
    "    word_or_vec, topn=10, least=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the most or least similar clusters for a given word or vector.\n",
    "\n",
    "    Args:\n",
    "        word_or_vec (Union[str, np.ndarray]): Word or vector to compare.\n",
    "        topn (int): Number of clusters to return.\n",
    "        least (bool): Whether to return least similar clusters.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, float]]: List of cluster indices and similarity scores.\n",
    "    \"\"\"\n",
    "    if isinstance(word_or_vec, str):\n",
    "        vector = model[word_or_vec]\n",
    "    elif isinstance(word_or_vec, np.ndarray):\n",
    "        vector = word_or_vec\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a string (word) or a NumPy array (vector).\")\n",
    "\n",
    "    # Compute similarities to all cluster centroids\n",
    "    cluster_similarities = {\n",
    "        cluster: 1 - distance.cosine(vector, centroid)\n",
    "        for cluster, centroid in cluster_centroid.items()\n",
    "    }\n",
    "    sorted_clusters = sort_dict(cluster_similarities, reverse=not least)\n",
    "    return list(sorted_clusters.items())[:topn]\n",
    "\n",
    "def print_similar_clusters(\n",
    "    word_or_vec, topn=10, least=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Print the most or least similar clusters for a given word or vector.\n",
    "\n",
    "    Args:\n",
    "        word_or_vec (Union[str, np.ndarray]): Word or vector to compare.\n",
    "        topn (int): Number of clusters to print.\n",
    "        least (bool): Whether to print least similar clusters.\n",
    "    \"\"\"\n",
    "    clusters = get_similar_clusters(word_or_vec, topn=topn, least=least)\n",
    "    for cluster, similarity in clusters:\n",
    "        if cluster in cluster_label:\n",
    "            print(f\"Cluster {cluster}: {cluster_label[cluster]} (Similarity: {similarity:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d927d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_similar_clusters(\"write\", topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimensions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
