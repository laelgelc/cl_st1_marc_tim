{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mfDwPd8WTKEq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfDwPd8WTKEq",
        "outputId": "0fbba8ac-4234-4ce6-b785-655f0aca2c7e"
      },
      "outputs": [],
      "source": [
        "# Execute if you are working in colab\n",
        "!pip install -qq numpy==1.26.4 gensim\n",
        "get_ipython().kernel.do_shutdown (restart=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0dbda1a",
      "metadata": {
        "id": "a0dbda1a"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the data (we assume that we have one sentence per line and that the tokens are separated by whitespace)\n",
        "\n",
        "with open(\"wue15.txt\", \"r\") as f:\n",
        "    data = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c113827",
      "metadata": {
        "id": "3c113827",
        "outputId": "d4d777ce-4895-448f-a53f-fdf7c92d357b"
      },
      "outputs": [],
      "source": [
        "# As we can see, the data is a list of strings, where each string is a line from the file.\n",
        "# Let's print the first 10 lines to see what we have.\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83884de2",
      "metadata": {
        "id": "83884de2",
        "outputId": "856e5687-dc55-4db2-c9d5-e95c9210a600"
      },
      "outputs": [],
      "source": [
        "# Now, we need to split each line into tokens. We can do this using the `split()` method, which splits a string into a list of words based on whitespace.\n",
        "# We will also remove any leading or trailing whitespace from each line.\n",
        "\n",
        "tokenized_data = []\n",
        "for line in data:\n",
        "    # Strip leading/trailing whitespace and split by whitespace\n",
        "    tokens = line.strip().split()\n",
        "    tokenized_data.append(tokens)\n",
        "\n",
        "# Alternatively, we could use a list comprehension to achieve the same result in a more compact way.\n",
        "# tokenized_data = [line.strip().split() for line in data]\n",
        "\n",
        "# Now, let's print the first 10 lines again to see the tokenized data.\n",
        "tokenized_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a884d0",
      "metadata": {
        "id": "a8a884d0"
      },
      "outputs": [],
      "source": [
        "# Now, we need to import the Gensim library to create a Word2Vec model using the tokenized data.\n",
        "from gensim.models import Word2Vec\n",
        "# We will create a Word2Vec model using the CBOW approach. The parameters are:\n",
        "# - `vector_size`: The size of the word vectors (we will use 200 dimensions).\n",
        "# - `window`: The maximum distance between the current and predicted word within a sentence (we will use a window of 5).\n",
        "# - `min_count`: Ignores all words with total frequency lower than this (we will use 5).\n",
        "# - `workers`: The number of worker threads to train the model (we will use all available cores except 1).\n",
        "# - `sg`: Skip-gram model (1) or CBOW (0). We will use CBOW (0).\n",
        "\n",
        "# get available cores\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count() - 1\n",
        "if cores > 50:\n",
        "    cores = 20\n",
        "\n",
        "# Create the Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_data, vector_size=200, window=5, min_count=5, workers=cores, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5005c202",
      "metadata": {
        "id": "5005c202"
      },
      "outputs": [],
      "source": [
        "# We can also save the model to a file for later use.\n",
        "model.save(\"wue15_word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c98466",
      "metadata": {
        "id": "25c98466"
      },
      "outputs": [],
      "source": [
        "# To load the model later, we can use the following command:\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load(\"wue15_word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba16274",
      "metadata": {
        "id": "8ba16274"
      },
      "outputs": [],
      "source": [
        "# The interesting part of the model is the `wv` attribute, which contains the word vectors.\n",
        "model = model.wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8df79ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8df79ee",
        "outputId": "c087d697-bbbc-4f32-8648-2af872750f57"
      },
      "outputs": [],
      "source": [
        "# Let's see if it worked by asking for nearest neighbors of a word.\n",
        "model.most_similar(\"attack\", topn=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89af5f2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89af5f2a",
        "outputId": "fa9e596d-956c-416d-cdaf-57b0fae763f9"
      },
      "outputs": [],
      "source": [
        "# Let's see how many words are in the vocabulary (= how many types from our training data occur at least 5 times in the corpus).\n",
        "print(f\"Vocabulary size: {len(model)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b897c302",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "b897c302",
        "outputId": "f0669a87-a8c4-43e4-c52c-da1ebf50cec4"
      },
      "outputs": [],
      "source": [
        "max_sents = 10\n",
        "printed = 0\n",
        "word = \"vendetta\"\n",
        "for sent in tokenized_data:\n",
        "    if word in sent:\n",
        "        print(\" \".join(sent))\n",
        "        printed += 1\n",
        "    if printed >= max_sents:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b9f6df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26b9f6df",
        "outputId": "ea707444-0c77-41f5-f8aa-67a62a95cc50"
      },
      "outputs": [],
      "source": [
        "# Let's now compare the model to a pre-trained one.\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "contrast_model = api.load(\"glove-wiki-gigaword-50\")\n",
        "contrast_model.most_similar(\"attack\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992bc829",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "992bc829",
        "outputId": "7d81c9a8-6497-40f7-d579-9e5a1b19e14a"
      },
      "outputs": [],
      "source": [
        "# Importantly, the vectors of the two models are not directly comparable, as they are trained independently.\n",
        "\n",
        "vector1 = model[\"attack\"]\n",
        "vector2 = contrast_model[\"attack\"]\n",
        "print(f\"Vector 1: {vector1[:10]}\")\n",
        "print(f\"Vector 2: {vector2[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7605c0d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "7605c0d9",
        "outputId": "25cb75c4-315d-4586-ce34-a2f8dc84f305"
      },
      "outputs": [],
      "source": [
        "# This will not work, as the vectors are not of the same size.\n",
        "# And even if they were, the nearest neighbours would not be meaningful as the models are independently trained.\n",
        "model.most_similar(vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c60db3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c60db3",
        "outputId": "f75e0216-70b8-4821-e35e-ae67fa5f4985"
      },
      "outputs": [],
      "source": [
        "# What you can do, however, is to contrast the two models by contrasting the nearest neighbours of a word.\n",
        "\n",
        "attack1 = [word_score[0] for word_score in model.most_similar(\"attack\", topn=20)]\n",
        "attack2 = [word_score[0] for word_score in contrast_model.most_similar(\"attack\", topn=20)]\n",
        "\n",
        "attack1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a387f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a387f6",
        "outputId": "e7e6ffa8-05c0-4633-ac97-b7a90accffb3"
      },
      "outputs": [],
      "source": [
        "for word in attack1:\n",
        "    if word not in attack2:\n",
        "        print(f\"Word {word} is in model 1 but not in model 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63fd4ca",
      "metadata": {
        "id": "b63fd4ca"
      },
      "outputs": [],
      "source": [
        "# Complete the following function that should return a percentage of overlapping words between two lists of words.\n",
        "def list_overlap(list1, list2):\n",
        "    # create an empty list to store the overlapping words\n",
        "    # use a for loop to iterate over the first list and check if each word is in the second list - if so, add it to the list of overlapping words\n",
        "    # divide the length of the list of overlapping words by the length of the first list\n",
        "    # and multiply by 100 to get the percentage\n",
        "    return overlap_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "badcbdf0",
      "metadata": {
        "id": "badcbdf0"
      },
      "outputs": [],
      "source": [
        "# And now integrate the previous steps and your list_overlap function into the function below.\n",
        "# It should take two words and two models as input and return the percentage of overlapping words among the n nearest neighbours of the words between the two models.\n",
        "\n",
        "def overlap_percentage(word, model1, model2, n=20):\n",
        "    # Get the n nearest neighbours of the word in both models\n",
        "    word1_neighbors = [word_score[0] for word_score in model1.most_similar(word, topn=n)]\n",
        "    word2_neighbors = [word_score[0] for word_score in model2.most_similar(word, topn=n)]\n",
        "    # Calculate the overlap percentage using the list_overlap function\n",
        "    overlap_percentage = list_overlap(word1_neighbors, word2_neighbors)\n",
        "    return overlap_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JFB5fej0Urfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFB5fej0Urfa",
        "outputId": "3c0906f7-df38-4012-d2ad-4c0f671a1d57"
      },
      "outputs": [],
      "source": [
        "# Now we can use the new function – What overlap percentages do you get?\n",
        "\n",
        "overlap_percentage(\"attack\", model, contrast_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9_TSWasMVZSn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_TSWasMVZSn",
        "outputId": "e2c53e21-8083-4cf2-fc3f-2e27c8fd62c1"
      },
      "outputs": [],
      "source": [
        "overlap_percentage(\"2000\", model, contrast_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ySrgK4_qVbdj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySrgK4_qVbdj",
        "outputId": "4a7585e9-4f3a-4613-aa53-a6292a1e85d3"
      },
      "outputs": [],
      "source": [
        "overlap_percentage(\"teenager\", model, contrast_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BfQpw3V5Wk9P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfQpw3V5Wk9P",
        "outputId": "583a44b3-b23e-44e4-dea1-7ab089fc5318"
      },
      "outputs": [],
      "source": [
        "model.most_similar(\"teenager\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yswD4-wPWm2s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yswD4-wPWm2s",
        "outputId": "e6df9a0b-5ac3-498b-f790-ba7bc994bdfd"
      },
      "outputs": [],
      "source": [
        "contrast_model.most_similar(\"teenager\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0fd56f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f0fd56f",
        "outputId": "13e06d51-8294-494b-9865-7976b975a2db"
      },
      "outputs": [],
      "source": [
        "# Now we can go from a corpus-based to a corpus-driven perspective and look at all words in the vocabulary.\n",
        "\n",
        "# We find the vocab of the model by using the `index_to_key` attribute.\n",
        "print(model.index_to_key[:10])\n",
        "\n",
        "# We build a set of words that are shared between the two models.\n",
        "\n",
        "shared_vocab = set(model.index_to_key).intersection(set(contrast_model.index_to_key))\n",
        "print(f\"Shared vocabulary size: {len(shared_vocab)}\")\n",
        "\n",
        "# Now we can iterate over the vocabulary and save the overlap percentages in a dictionary.\n",
        "overlap_dict = {}\n",
        "\n",
        "max_words = 1000 # set to len(shared_vocab) to use the whole vocab\n",
        "i = 0\n",
        "for word in shared_vocab:\n",
        "    overlap = overlap_percentage(word, model, contrast_model)\n",
        "    overlap_dict[word] = overlap\n",
        "    i += 1\n",
        "    if i >= max_words:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581ee010",
      "metadata": {
        "id": "581ee010"
      },
      "outputs": [],
      "source": [
        "# Now we can sort the dictionary with this function\n",
        "\n",
        "def sort_dict(dic, reverse=True):\n",
        "    return dict(sorted(dic.items(), key=lambda item: item[1], reverse=reverse))\n",
        "\n",
        "sorted_overlap = sort_dict(overlap_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a394d0b2",
      "metadata": {
        "id": "a394d0b2"
      },
      "outputs": [],
      "source": [
        "sorted_overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078954d3",
      "metadata": {
        "id": "078954d3"
      },
      "outputs": [],
      "source": [
        "sort_dict(overlap_dict, reverse=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b981801b",
      "metadata": {
        "id": "b981801b"
      },
      "outputs": [],
      "source": [
        "model.most_similar(\"spongebob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b03f719",
      "metadata": {
        "id": "7b03f719"
      },
      "outputs": [],
      "source": [
        "contrast_model.most_similar(\"spongebob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e06f81",
      "metadata": {
        "id": "b8e06f81"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dimensions",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
